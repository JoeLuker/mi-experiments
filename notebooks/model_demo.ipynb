{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Emphasis and Analysis Demo\n",
    "\n",
    "This notebook demonstrates the key features of the model emphasis, analysis, and generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jluker/mi-experiments/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "\n",
    "from mi_experiments.utils.loading import load\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "from mlx_lm.tokenizer_utils import TokenizerWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 125470.63it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the model\n",
    "model, tokenizer = load(\"mlx-community/Mistral-7B-Instruct-v0.3-4bit\")\n",
    "\n",
    "# Utility functions\n",
    "def create_additive_causal_mask(N: int, offset: int = 0):\n",
    "    rinds = mx.arange(offset + N)\n",
    "    linds = mx.arange(offset, offset + N) if offset else rinds\n",
    "    mask = linds[:, None] < rinds[None]\n",
    "    return mask * -1e9\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    model_type: str\n",
    "    hidden_size: int\n",
    "    num_hidden_layers: int\n",
    "    intermediate_size: int\n",
    "    num_attention_heads: int\n",
    "    rms_norm_eps: float\n",
    "    vocab_size: int\n",
    "    head_dim: Optional[int] = None\n",
    "    max_position_embeddings: Optional[int] = None\n",
    "    num_key_value_heads: Optional[int] = None\n",
    "    attention_bias: bool = False\n",
    "    mlp_bias: bool = False\n",
    "    rope_theta: float = 10000\n",
    "    rope_traditional: bool = False\n",
    "    rope_scaling: Optional[Dict[str, Union[float, str]]] = None\n",
    "    tie_word_embeddings: bool = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_model(cls, model: nn.Module):\n",
    "        return cls(\n",
    "            model_type=model.model_type,\n",
    "            hidden_size=model.args.hidden_size,\n",
    "            num_hidden_layers=model.args.num_hidden_layers,\n",
    "            intermediate_size=model.args.intermediate_size,\n",
    "            num_attention_heads=model.args.num_attention_heads,\n",
    "            rms_norm_eps=model.args.rms_norm_eps,\n",
    "            vocab_size=model.args.vocab_size,\n",
    "            head_dim=model.head_dim,\n",
    "            num_key_value_heads=model.n_kv_heads,\n",
    "            tie_word_embeddings=model.args.tie_word_embeddings\n",
    "        )\n",
    "\n",
    "# Extract model arguments\n",
    "model_args = ModelArgs.from_model(model)\n",
    "\n",
    "# Ensure tokenizer is wrapped\n",
    "if not isinstance(tokenizer, TokenizerWrapper):\n",
    "    tokenizer = TokenizerWrapper(tokenizer)\n",
    "\n",
    "def format_prompt(prompt: str) -> str:\n",
    "    return f\"[INST] {prompt} [/INST]\"\n",
    "\n",
    "def extract_generated_text(full_text: str) -> str:\n",
    "    match = re.search(r'\\[/INST\\]\\s*(.*)', full_text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: 270.917 tokens-per-second\n",
      "Generation: 6710.119 tokens-per-second\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters A and Y. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"any\":\n",
      "\n",
      "1. \"Can you bring\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters D and J. Then, say 3 sentences which use the word.\n",
      "1. The dog jumped over the ditch.\n",
      "2. The DJ played a jaz\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters S and X. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"exotic\":\n",
      "\n",
      "1. \"The exotic\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters D and G. Then, say 3 sentences which use the word.\n",
      "1. The dog is digging a hole in the garden.\n",
      "\n",
      "2. The doctor gave\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters C and T. Then, say 3 sentences which use the word.\n",
      "1. The cat chased the mouse across the mat.\n",
      "2. The teacher corrected the\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters M and W. Then, say 3 sentences which use the word.\n",
      "1. \"Melissa was walking through the mall, marveling at the winter wonder\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters A and I. Then, say 3 sentences which use the word.\n",
      "Apple, I am an apple. I eat an apple every day. The apple is red.\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters W and Z. Then, say 3 sentences which use the word.\n",
      "Word: Puzzle\n",
      "\n",
      "1. The crossword puzzle was too difficult for me to solve\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters L and S. Then, say 3 sentences which use the word.\n",
      "1. The library is a place where people can borrow books, read, and learn new things\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters A and Z. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"pizza\":\n",
      "\n",
      "1. \"I love\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters B and U. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Buoy\n",
      "\n",
      "1. The buoy in the harbor signaled that the water\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters F and Z. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Safari (noun)\n",
      "\n",
      "1. The safari in Africa was an un\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters C and G. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Circus\n",
      "\n",
      "1. The circus was a magical place where children could enjoy ac\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters R and T. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: \"Trout\"\n",
      "\n",
      "1. The trout was swimming gracefully in the crystal\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters C and X. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Caramel (pronounced with a hard 'c' as in 'cat')\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters D and W. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Puddle\n",
      "\n",
      "1. After the heavy rain, the children enjoyed splashing in\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters L and R. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Lumber\n",
      "\n",
      "1. The carpenter carefully measured the lumber before cutting it\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters I and Q. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Unique\n",
      "\n",
      "1. The painting in the museum was so unique that it stood out\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters P and V. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Penguin\n",
      "\n",
      "1. The penguin waddled across the icy\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters E and I. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: \"Envelope\"\n",
      "\n",
      "1. I carefully sealed the letter in an envelope before dropping\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "from mi_experiments.inference.batch_manager import batch_generate\n",
    "\n",
    "capital_letters = string.ascii_uppercase\n",
    "distinct_pairs = [(a, b) for i, a in enumerate(capital_letters) for b in capital_letters[i + 1:]]\n",
    "\n",
    "num_prompts = 10\n",
    "prompt_template = \"Think of a real word containing both the letters {l1} and {l2}. Then, say 3 sentences which use the word.\"\n",
    "prompts_raw = [prompt_template.format(l1=p[0], l2=p[1]) for p in random.sample(distinct_pairs, num_prompts)]\n",
    "prompt_template_2 = \"Come up with a real English word containing both the letters {l1} and {l2}. No acronyms. Then, give 3 complete sentences which use the word.\"\n",
    "prompts_raw_2 = [prompt_template_2.format(l1=p[0], l2=p[1]) for p in random.sample(distinct_pairs, num_prompts)]\n",
    "\n",
    "response = batch_generate(model, tokenizer, prompts=prompts_raw[:10]+prompts_raw_2[:10], max_tokens=20, verbose=True, temp=0.0)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
