{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Emphasis and Analysis Demo\n",
    "\n",
    "This notebook demonstrates the key features of the model emphasis, analysis, and generation capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jluker/mi-experiments/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "\n",
    "from mi_experiments.utils.loading import load\n",
    "\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Union\n",
    "\n",
    "from mlx_lm.tokenizer_utils import TokenizerWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 7 files: 100%|██████████| 7/7 [00:00<00:00, 146070.29it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the model\n",
    "model, tokenizer = load(\"mlx-community/Mistral-7B-Instruct-v0.3-4bit\")\n",
    "\n",
    "# Utility functions\n",
    "def create_additive_causal_mask(N: int, offset: int = 0):\n",
    "    rinds = mx.arange(offset + N)\n",
    "    linds = mx.arange(offset, offset + N) if offset else rinds\n",
    "    mask = linds[:, None] < rinds[None]\n",
    "    return mask * -1e9\n",
    "\n",
    "@dataclass\n",
    "class ModelArgs:\n",
    "    model_type: str\n",
    "    hidden_size: int\n",
    "    num_hidden_layers: int\n",
    "    intermediate_size: int\n",
    "    num_attention_heads: int\n",
    "    rms_norm_eps: float\n",
    "    vocab_size: int\n",
    "    head_dim: Optional[int] = None\n",
    "    max_position_embeddings: Optional[int] = None\n",
    "    num_key_value_heads: Optional[int] = None\n",
    "    attention_bias: bool = False\n",
    "    mlp_bias: bool = False\n",
    "    rope_theta: float = 10000\n",
    "    rope_traditional: bool = False\n",
    "    rope_scaling: Optional[Dict[str, Union[float, str]]] = None\n",
    "    tie_word_embeddings: bool = True\n",
    "\n",
    "    @classmethod\n",
    "    def from_model(cls, model: nn.Module):\n",
    "        return cls(\n",
    "            model_type=model.model_type,\n",
    "            hidden_size=model.args.hidden_size,\n",
    "            num_hidden_layers=model.args.num_hidden_layers,\n",
    "            intermediate_size=model.args.intermediate_size,\n",
    "            num_attention_heads=model.args.num_attention_heads,\n",
    "            rms_norm_eps=model.args.rms_norm_eps,\n",
    "            vocab_size=model.args.vocab_size,\n",
    "            head_dim=model.head_dim,\n",
    "            num_key_value_heads=model.n_kv_heads,\n",
    "            tie_word_embeddings=model.args.tie_word_embeddings\n",
    "        )\n",
    "\n",
    "# Extract model arguments\n",
    "model_args = ModelArgs.from_model(model)\n",
    "\n",
    "# Ensure tokenizer is wrapped\n",
    "if not isinstance(tokenizer, TokenizerWrapper):\n",
    "    tokenizer = TokenizerWrapper(tokenizer)\n",
    "\n",
    "def format_prompt(prompt: str) -> str:\n",
    "    return f\"[INST] {prompt} [/INST]\"\n",
    "\n",
    "def extract_generated_text(full_text: str) -> str:\n",
    "    match = re.search(r'\\[/INST\\]\\s*(.*)', full_text, re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: 276.779 tokens-per-second\n",
      "Generation: 5926.328 tokens-per-second\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters C and F. Then, say 3 sentences which use the word.\n",
      "1. The cat chased the fox through the forest.\n",
      "2. The chef cooked\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters R and Y. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"Rhythm\":\n",
      "\n",
      "1. \"The rhythm\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters B and S. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"Basket\":\n",
      "\n",
      "1. \"Basket\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters N and V. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"November\":\n",
      "\n",
      "1. \"November\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters F and V. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"future\":\n",
      "\n",
      "1. \"The future of\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters I and X. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"ixnay\":\n",
      "\n",
      "1. \"The\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters T and Z. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"pizza\":\n",
      "\n",
      "1. \"The pizza\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters D and F. Then, say 3 sentences which use the word.\n",
      "1. The dog found a bone in the field.\n",
      "\n",
      "2. The teacher wrote the\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters T and W. Then, say 3 sentences which use the word.\n",
      "1. The tall tower was a wonderful sight to see.\n",
      "2. The twins were\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters A and M. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"America\":\n",
      "\n",
      "1. \"America is a\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters A and K. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Bakery\n",
      "\n",
      "1. The local bakery sells a variety of freshly\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters I and J. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Jewel\n",
      "\n",
      "1. The jewelry store displayed a wide variety of beautiful jewels for\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters U and X. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Xylophone\n",
      "\n",
      "1. The xylophone is a musical instrument that\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters Q and T. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Quilt\n",
      "\n",
      "1. She spent the weekend meticulously quilting the intr\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters O and W. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: \"Mow\"\n",
      "\n",
      "1. After a long day at work, John decided to\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters A and C. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Acorn\n",
      "\n",
      "1. The squirrel carefully gathered acorns for the winter\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters B and N. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Banana\n",
      "\n",
      "1. I love to eat bananas as a healthy snack in\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters W and Y. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Twyford (a town in England)\n",
      "\n",
      "1. I recently visited the charming\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters K and W. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Kangaroo\n",
      "\n",
      "1. The kangaroo is a marsupial\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters C and Y. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Cycle\n",
      "\n",
      "1. After a long day at work, I like to take a\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import random\n",
    "from mi_experiments.inference.batch_manager import batch_generate\n",
    "\n",
    "capital_letters = string.ascii_uppercase\n",
    "distinct_pairs = [(a, b) for i, a in enumerate(capital_letters) for b in capital_letters[i + 1:]]\n",
    "\n",
    "num_prompts = 10\n",
    "prompt_template = \"Think of a real word containing both the letters {l1} and {l2}. Then, say 3 sentences which use the word.\"\n",
    "prompts_raw = [prompt_template.format(l1=p[0], l2=p[1]) for p in random.sample(distinct_pairs, num_prompts)]\n",
    "prompt_template_2 = \"Come up with a real English word containing both the letters {l1} and {l2}. No acronyms. Then, give 3 complete sentences which use the word.\"\n",
    "prompts_raw_2 = [prompt_template_2.format(l1=p[0], l2=p[1]) for p in random.sample(distinct_pairs, num_prompts)]\n",
    "\n",
    "response = batch_generate(model, tokenizer, prompts=prompts_raw[:10]+prompts_raw_2[:10], max_tokens=20, verbose=True, temp=0.0)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========\n",
      "Prompt: 254.875 tokens-per-second\n",
      "Generation: 5562.947 tokens-per-second\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters C and F. Then, say 3 sentences which use the word.\n",
      "1. The cat chased the fox through the forest.\n",
      "2. The chef cooked\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters R and Y. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"Rhythm\":\n",
      "\n",
      "1. \"The rhythm\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters B and S. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"Basket\":\n",
      "\n",
      "1. \"John loves\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters N and V. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"November\":\n",
      "\n",
      "1. \"November\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters F and V. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"future\":\n",
      "\n",
      "1. \"The future of\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters I and X. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"ixnay\":\n",
      "\n",
      "1. \"The\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters T and Z. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"pizza\":\n",
      "\n",
      "1. \"The pizza\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters D and F. Then, say 3 sentences which use the word.\n",
      "1. The dog found a bone in the field.\n",
      "\n",
      "2. The teacher wrote the\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters T and W. Then, say 3 sentences which use the word.\n",
      "1. The tall tower was a wonderful sight to see.\n",
      "2. The twins were\n",
      "==========\n",
      "Prompt: Think of a real word containing both the letters A and M. Then, say 3 sentences which use the word.\n",
      "Sure, here are three sentences using the word \"America\":\n",
      "\n",
      "1. \"America is a\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters A and K. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Bakery\n",
      "\n",
      "1. The local bakery sells a variety of freshly\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters I and J. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Jewel\n",
      "\n",
      "1. The jewelry store displayed a wide variety of beautiful jewels for\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters U and X. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Xylophone\n",
      "\n",
      "1. The xylophone is a musical instrument that\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters Q and T. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Quilt\n",
      "\n",
      "1. She spent the weekend meticulously quilting the intr\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters O and W. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: \"Mow\"\n",
      "\n",
      "1. After a long day at work, John decided to\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters A and C. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Acorn\n",
      "\n",
      "1. The squirrel carefully gathered acorns for the winter\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters B and N. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Banana\n",
      "\n",
      "1. I love to eat bananas as a healthy snack in\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters W and Y. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Twyford (a town in England)\n",
      "\n",
      "1. I recently visited the charming\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters K and W. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Kangaroo\n",
      "\n",
      "1. The kangaroo is a marsupial\n",
      "==========\n",
      "Prompt: Come up with a real English word containing both the letters C and Y. No acronyms. Then, give 3 complete sentences which use the word.\n",
      "Word: Cycle\n",
      "\n",
      "1. After a long day at work, I like to take a\n"
     ]
    }
   ],
   "source": [
    "# Generate with emphasis on specific layers\n",
    "emphasis_config = {\n",
    "    'layers': {\n",
    "        '0': 1.0,  # Boost first layer\n",
    "        '1': 1.0,  # Reduce second layer\n",
    "        '30': 1.0,  # Zero out thirtyith layer\n",
    "    },\n",
    "    'heads': {\n",
    "        '0': {'0': 1.0, '1': 0.5},  # Modify attention heads in first layer\n",
    "    },\n",
    "    'neurons': {\n",
    "        '1': {'10': 0.0, '20': 2.0}  # Modify neurons in second layer\n",
    "    }\n",
    "}\n",
    "\n",
    "# Apply emphasis configuration\n",
    "model.set_emphasis_config(emphasis_config)\n",
    "\n",
    "# Generate with modified model\n",
    "response_emphasized = batch_generate(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    prompts=prompts_raw[:10]+prompts_raw_2[:10],\n",
    "    max_tokens=20,\n",
    "    verbose=True,\n",
    "    temp=0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
